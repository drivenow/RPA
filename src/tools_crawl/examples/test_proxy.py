#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çš„ä»£ç†æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯mitmdumpæ˜¯å¦æ­£ç¡®æ•è·HTTPè¯·æ±‚
"""

import requests
import time

def test_proxy_capture():
    """æµ‹è¯•ä»£ç†æ•è·åŠŸèƒ½"""
    
    # é…ç½®ä»£ç†
    proxies = {
        'http': 'http://127.0.0.1:8080',
        'https': 'http://127.0.0.1:8080'
    }
    
    # ç¦ç”¨SSLéªŒè¯ï¼ˆå› ä¸ºä½¿ç”¨äº†--ssl-insecureï¼‰
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    
    print("ğŸš€ å¼€å§‹æµ‹è¯•ä»£ç†æ•è·åŠŸèƒ½...")
    print(f"ä»£ç†é…ç½®: {proxies}")
    
    # æµ‹è¯•URLåˆ—è¡¨
    test_urls = [
        "https://www.xiaohongshu.com/explore",
        "https://search.bilibili.com/all?keyword=zhoujielun%E5%91%A8%E6%9D%B0%E4%BC%A6&from_source=webtop_search&spm_id_from=333.1007&search_source=5"
    ]
    
    for i, url in enumerate(test_urls, 1):
        try:
            print(f"\nğŸ“¡ æµ‹è¯• {i}/{len(test_urls)}: {url}")
            
            response = requests.get(
                url, 
                proxies=proxies, 
                verify=False,  # ç¦ç”¨SSLéªŒè¯
                timeout=10,
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
            )
            
            print(f"âœ… å“åº”çŠ¶æ€: {response.status_code}")
            print(f"ğŸ“Š å“åº”å¤§å°: {len(response.content)} bytes")
            
            # ç­‰å¾…ä¸€ä¸‹è®©mitmproxyå¤„ç†
            time.sleep(2)
            
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
    
    print("\nğŸ¯ æµ‹è¯•å®Œæˆï¼è¯·æ£€æŸ¥mitmdumpæ§åˆ¶å°è¾“å‡ºå’Œcaptured_dataç›®å½•")

if __name__ == "__main__":
    test_proxy_capture()