#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ“åŒ…æ•°æ®éªŒè¯è„šæœ¬
å¿«é€ŸéªŒè¯capture_traffic.pyæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import json
import os
import time
from pathlib import Path
from datetime import datetime, timedelta

def log(message, level="INFO"):
    """æ—¥å¿—è¾“å‡º"""
    timestamp = time.strftime("%H:%M:%S")
    print(f"[{timestamp}] [{level}] {message}")

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
    log("ğŸ” æ£€æŸ¥ç¯å¢ƒé…ç½®...")
    
    issues = []
    
    # æ£€æŸ¥mitmproxy
    try:
        import mitmproxy
        try:
            version = mitmproxy.__version__
        except AttributeError:
            # æŸäº›ç‰ˆæœ¬çš„mitmproxyæ²¡æœ‰__version__å±æ€§
            version = "å·²å®‰è£…"
        log(f"âœ… mitmproxy: {version}")
    except ImportError:
        issues.append("âŒ æœªå®‰è£…mitmproxy")
    
    # æ£€æŸ¥capture_traffic.pyæ–‡ä»¶
    capture_file = Path("examples/capture_traffic.py")
    if capture_file.exists():
        log(f"âœ… æ‰¾åˆ°æŠ“åŒ…è„šæœ¬: {capture_file}")
    else:
        issues.append(f"âŒ æœªæ‰¾åˆ°æŠ“åŒ…è„šæœ¬: {capture_file}")
    
    # æ£€æŸ¥è¾“å‡ºç›®å½•
    output_dir = Path("captured_data")
    if output_dir.exists():
        log(f"âœ… è¾“å‡ºç›®å½•å­˜åœ¨: {output_dir}")
    else:
        log(f"âš ï¸  è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_dir} (è¿è¡Œæ—¶ä¼šè‡ªåŠ¨åˆ›å»º)")
    
    return issues

def analyze_captured_data():
    """åˆ†ææŠ“åŒ…æ•°æ®"""
    log("ğŸ“Š åˆ†ææŠ“åŒ…æ•°æ®...")
    
    captured_dir = Path("captured_data")
    if not captured_dir.exists():
        log("âŒ æœªæ‰¾åˆ°captured_dataç›®å½•")
        return False
    
    # æŸ¥æ‰¾JSONæ–‡ä»¶
    json_files = list(captured_dir.glob("captured_*.json"))
    
    if not json_files:
        log("âŒ æœªæ‰¾åˆ°æŠ“åŒ…æ•°æ®æ–‡ä»¶")
        log("ğŸ’¡ æç¤º: è¯·å…ˆè¿è¡ŒmitmproxyæŠ“åŒ…åå†éªŒè¯")
        return False
    
    log(f"ğŸ“ æ‰¾åˆ° {len(json_files)} ä¸ªæ•°æ®æ–‡ä»¶")
    
    # åˆ†ææœ€æ–°æ–‡ä»¶
    latest_file = max(json_files, key=lambda f: f.stat().st_mtime)
    file_time = datetime.fromtimestamp(latest_file.stat().st_mtime)
    
    log(f"ğŸ“„ æœ€æ–°æ–‡ä»¶: {latest_file.name}")
    log(f"ğŸ•’ ä¿®æ”¹æ—¶é—´: {file_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯æœ€è¿‘ç”Ÿæˆçš„
    if datetime.now() - file_time > timedelta(hours=1):
        log("âš ï¸  æœ€æ–°æ–‡ä»¶è¶…è¿‡1å°æ—¶ï¼Œå¯èƒ½ä¸æ˜¯å½“å‰æµ‹è¯•æ•°æ®")
    
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # åˆ†ææ•°æ®ç»“æ„
        stats = data.get("capture_stats", {})
        captured_data = data.get("captured_data", [])
        
        log("ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        log(f"   æ€»è¯·æ±‚æ•°: {stats.get('total_requests', 0)}")
        log(f"   æ€»å“åº”æ•°: {stats.get('total_responses', 0)}")
        log(f"   æ•è·æ•°æ®: {stats.get('captured_count', 0)}æ¡")
        log(f"   æµ‹è¯•æ¨¡å¼: {stats.get('test_mode', False)}")
        log(f"   å¼€å§‹æ—¶é—´: {stats.get('start_time', 'N/A')}")
        
        if not captured_data:
            log("âŒ æŠ“åŒ…æ–‡ä»¶ä¸ºç©º")
            return False
        
        log(f"âœ… æˆåŠŸæ•è· {len(captured_data)} æ¡æ•°æ®")
        
        # åˆ†ææ•°æ®å†…å®¹
        analyze_data_content(captured_data)
        
        return True
        
    except json.JSONDecodeError as e:
        log(f"âŒ JSONè§£æå¤±è´¥: {e}", "ERROR")
        return False
    except Exception as e:
        log(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}", "ERROR")
        return False

def analyze_data_content(captured_data):
    """åˆ†ææŠ“åŒ…æ•°æ®å†…å®¹"""
    log("\nğŸ” æ•°æ®å†…å®¹åˆ†æ:")
    
    # ç»Ÿè®¡åŸŸå
    domains = {}
    methods = {}
    status_codes = {}
    
    for item in captured_data:
        url = item.get("url", "")
        method = item.get("method", "")
        status = item.get("response", {}).get("status_code", 0)
        
        # æå–åŸŸå
        if "://" in url:
            domain = url.split("://")[1].split("/")[0]
            domains[domain] = domains.get(domain, 0) + 1
        
        # ç»Ÿè®¡æ–¹æ³•
        if method:
            methods[method] = methods.get(method, 0) + 1
        
        # ç»Ÿè®¡çŠ¶æ€ç 
        if status:
            status_codes[status] = status_codes.get(status, 0) + 1
    
    # æ˜¾ç¤ºåŸŸåç»Ÿè®¡
    if domains:
        log("ğŸ“ åŸŸååˆ†å¸ƒ:")
        for domain, count in sorted(domains.items(), key=lambda x: x[1], reverse=True):
            log(f"   {domain}: {count}æ¬¡")
    
    # æ˜¾ç¤ºæ–¹æ³•ç»Ÿè®¡
    if methods:
        log("ğŸ”§ è¯·æ±‚æ–¹æ³•:")
        for method, count in methods.items():
            log(f"   {method}: {count}æ¬¡")
    
    # æ˜¾ç¤ºçŠ¶æ€ç ç»Ÿè®¡
    if status_codes:
        log("ğŸ“Š å“åº”çŠ¶æ€:")
        for status, count in status_codes.items():
            log(f"   {status}: {count}æ¬¡")
    
    # æ£€æŸ¥å…³é”®API
    api_patterns = [
        "homefeed", "feed", "explore", "api", "web_api"
    ]
    
    found_apis = []
    for item in captured_data:
        url = item.get("url", "")
        for pattern in api_patterns:
            if pattern in url.lower():
                found_apis.append((pattern, url))
                break
    
    if found_apis:
        log("ğŸ¯ å‘ç°å…³é”®API:")
        pattern_count = {}
        for pattern, url in found_apis:
            pattern_count[pattern] = pattern_count.get(pattern, 0) + 1
        
        for pattern, count in pattern_count.items():
            log(f"   {pattern}: {count}ä¸ª")
        
        # æ˜¾ç¤ºéƒ¨åˆ†URLç¤ºä¾‹
        log("ğŸ“ URLç¤ºä¾‹:")
        for pattern, url in found_apis[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            short_url = url[:80] + "..." if len(url) > 80 else url
            log(f"   [{pattern}] {short_url}")
    else:
        log("âš ï¸  æœªå‘ç°å…³é”®APIè°ƒç”¨")

def check_recent_activity():
    """æ£€æŸ¥æœ€è¿‘æ´»åŠ¨"""
    log("\nâ° æ£€æŸ¥æœ€è¿‘æ´»åŠ¨...")
    
    captured_dir = Path("captured_data")
    if not captured_dir.exists():
        return
    
    now = datetime.now()
    recent_files = []
    
    for file in captured_dir.glob("captured_*.json"):
        file_time = datetime.fromtimestamp(file.stat().st_mtime)
        if now - file_time < timedelta(minutes=30):  # 30åˆ†é’Ÿå†…
            recent_files.append((file, file_time))
    
    if recent_files:
        log(f"ğŸ“… æœ€è¿‘30åˆ†é’Ÿå†…æœ‰ {len(recent_files)} ä¸ªæ–‡ä»¶:")
        for file, file_time in sorted(recent_files, key=lambda x: x[1], reverse=True):
            log(f"   {file.name} - {file_time.strftime('%H:%M:%S')}")
    else:
        log("ğŸ“… æœ€è¿‘30åˆ†é’Ÿå†…æ— æ–°æ–‡ä»¶")

def provide_suggestions():
    """æä¾›å»ºè®®"""
    log("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    log("1. å¦‚æœæ²¡æœ‰æ•°æ®æ–‡ä»¶:")
    log("   - ç¡®ä¿mitmproxyæ­£åœ¨è¿è¡Œ")
    log("   - æ£€æŸ¥ä»£ç†é…ç½®æ˜¯å¦æ­£ç¡®")
    log("   - è®¿é—®å°çº¢ä¹¦é¡µé¢è§¦å‘APIè°ƒç”¨")
    log("")
    log("2. å¦‚æœæ•°æ®ä¸ºç©º:")
    log("   - æ£€æŸ¥åŸŸåè¿‡æ»¤é…ç½®")
    log("   - ç¡®è®¤è®¿é—®çš„æ˜¯æ­£ç¡®çš„é¡µé¢")
    log("   - æŸ¥çœ‹mitmproxyæ§åˆ¶å°è¾“å‡º")
    log("")
    log("3. æµ‹è¯•å‘½ä»¤:")
    log("   - å¯åŠ¨ä»£ç†: python -m mitmproxy.tools.mitmdump -s examples/capture_traffic.py -p 8080")
    log("   - å®Œæ•´æµ‹è¯•: python examples/test_capture.py")
    log("   - éªŒè¯æ•°æ®: python examples/verify_capture.py")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æŠ“åŒ…æ•°æ®éªŒè¯å·¥å…·")
    print("å¿«é€Ÿæ£€æŸ¥capture_traffic.pyçš„å·¥ä½œçŠ¶æ€")
    print("-" * 60)
    
    # 1. æ£€æŸ¥ç¯å¢ƒ
    issues = check_environment()
    if issues:
        log("âŒ ç¯å¢ƒæ£€æŸ¥å‘ç°é—®é¢˜:")
        for issue in issues:
            log(f"   {issue}")
        log("")
    
    # 2. åˆ†ææ•°æ®
    has_data = analyze_captured_data()
    
    # 3. æ£€æŸ¥æœ€è¿‘æ´»åŠ¨
    check_recent_activity()
    
    # 4. æä¾›å»ºè®®
    provide_suggestions()
    
    # 5. æ€»ç»“
    log("\n" + "="*60)
    if has_data and not issues:
        log("âœ… éªŒè¯å®Œæˆ: æŠ“åŒ…åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    elif has_data:
        log("âš ï¸  éªŒè¯å®Œæˆ: æŠ“åŒ…æœ‰æ•°æ®ä½†ç¯å¢ƒæœ‰é—®é¢˜")
    else:
        log("âŒ éªŒè¯å®Œæˆ: æœªå‘ç°æœ‰æ•ˆæŠ“åŒ…æ•°æ®")
    log("="*60)

if __name__ == "__main__":
    main()